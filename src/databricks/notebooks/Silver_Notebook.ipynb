{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6bdf60c-d663-48f0-a6fc-941594136d4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b546070a-ab0c-4828-b110-f671034222aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa446748-1bef-48c3-a35b-bc408b8bedb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2106b66-992d-4e1b-a8d2-f1533b44310d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDCC2 Processing month: OCT\n✅ OCT Silver layer saved to abfss://silver@ecommerceprojectdl.dfs.core.windows.net/month_Oct/\n\uD83D\uDCC2 Processing month: NOV\n✅ NOV Silver layer saved to abfss://silver@ecommerceprojectdl.dfs.core.windows.net/month_Nov/\n\uD83C\uDFAF All months successfully processed to Silver Layer!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "months = [\"Oct\", \"Nov\"]\n",
    "\n",
    "for month in months:\n",
    "    print(f\"\uD83D\uDCC2 Processing month: {month.upper()}\")\n",
    "\n",
    "    input_path = f\"abfss://bronze@ecommerceprojectdl.dfs.core.windows.net/month_{month}\"\n",
    "    output_path = f\"abfss://silver@ecommerceprojectdl.dfs.core.windows.net/month_{month}/\"\n",
    "\n",
    "    # 1️⃣ Read\n",
    "    df = (spark.read.format(\"csv\")\n",
    "          .option(\"header\", True)\n",
    "          .option(\"inferSchema\", True)\n",
    "          .load(input_path))\n",
    "\n",
    "    # 2️⃣ Transform\n",
    "    df_silver = (\n",
    "        df\n",
    "        .withColumn(\"event_time\", F.to_timestamp(\"event_time\"))\n",
    "        .withColumn(\"product_id\", F.col(\"product_id\").cast(LongType()))\n",
    "        .withColumn(\"category_id\", F.col(\"category_id\").cast(LongType()))\n",
    "        .withColumn(\"price\", F.col(\"price\").cast(DoubleType()))\n",
    "        .withColumn(\"user_id\", F.col(\"user_id\").cast(LongType()))\n",
    "        .withColumn(\"event_type\", F.lower(F.trim(F.col(\"event_type\"))))\n",
    "        .withColumn(\"brand\", F.lower(F.trim(F.coalesce(F.col(\"brand\"), F.lit(\"unknown\")))))\n",
    "        .withColumn(\"category_code\", F.trim(F.col(\"category_code\")))\n",
    "        .withColumn(\"event_date\", F.to_date(\"event_time\"))\n",
    "        .withColumn(\"event_time_only\", F.date_format(\"event_time\", \"HH:mm:ss\"))\n",
    "        .withColumn(\"parts\", F.split(F.col(\"category_code\"), r\"\\.\"))\n",
    "        .withColumn(\"main_category\", F.try_element_at(F.col(\"parts\"), F.lit(1)))\n",
    "        .withColumn(\"sub_category\", F.try_element_at(F.col(\"parts\"), F.lit(2)))\n",
    "        .withColumn(\"item_category\", F.try_element_at(F.col(\"parts\"), F.lit(3)))\n",
    "        .drop(\"parts\")\n",
    "        .dropDuplicates()\n",
    "    )\n",
    "\n",
    "    # 3️⃣ Fill Nulls\n",
    "    df_silver = df_silver.fillna({\n",
    "        \"category_code\": \"unknown\",\n",
    "        \"main_category\": \"unknown\",\n",
    "        \"sub_category\": \"unknown\",\n",
    "        \"item_category\": \"unknown\"\n",
    "    })\n",
    "\n",
    "    # 4️⃣ Write as Delta\n",
    "    df_silver.write.format(\"delta\").mode(\"overwrite\").save(output_path)\n",
    "\n",
    "    print(f\"✅ {month.upper()} Silver layer saved to {output_path}\")\n",
    "\n",
    "print(\"\uD83C\uDFAF All months successfully processed to Silver Layer!\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Silver_Notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}